<!DOCTYPE html>
<html>
<head>
    <title>SL FacialID Bridge v3.6.1</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.15/dist/face-api.js"></script>
    <style>
        body { background: #4e73df; color: white; display: flex; align-items: center; justify-content: center; height: 100vh; margin: 0; font-family: 'Segoe UI', sans-serif; }
        .bridge-card { background: white; color: #333; padding: 30px; border-radius: 15px; box-shadow: 0 15px 35px rgba(0,0,0,0.3); text-align: center; width: 420px; }
        #v-wrap { position: relative; width: 100%; height: 280px; background: #000; border-radius: 10px; overflow: hidden; margin-bottom: 15px; border: 3px solid #eee; }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }
        .status-badge { font-size: 0.85rem; padding: 8px 15px; border-radius: 20px; font-weight: bold; transition: all 0.3s ease; }
        .loading-spinner { width: 18px; height: 18px; border: 3px solid #f3f3f3; border-top: 3px solid #3498db; border-radius: 50%; display: inline-block; animation: spin 1s linear infinite; margin-right: 10px; vertical-align: middle; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body>

<div class="bridge-card">
    <h5 class="fw-bold text-primary mb-3">FACIAL VERIFICATION</h5>
    
    <div id="v-wrap">
        <video id="video" autoplay muted playsinline></video>
    </div>

    <div id="statusBox" class="status-badge bg-light text-secondary mb-3">
        <div id="spinner" class="loading-spinner"></div>
        <span id="statusText">Downloading AI Engine...</span>
    </div>

    <button id="btn" class="btn btn-primary w-100 fw-bold py-3 shadow" disabled>INITIALIZING...</button>
</div>

<script>
    const params = new URLSearchParams(window.location.search);
    const action = params.get('action');
    const icid = params.get('icid');
    const savedBio = params.get('bioId'); 
    const returnUrl = params.get('returnUrl');
    const station = params.get('station');

    const video = document.getElementById('video');
    const statusText = document.getElementById('statusText');
    const statusBox = document.getElementById('statusBox');
    const btn = document.getElementById('btn');
    const spinner = document.getElementById('spinner');

    async function init() {
        // 1. Wait for Library to exist in global scope
        if (typeof faceapi === 'undefined') {
            console.log("AI Library not detected yet, retrying...");
            setTimeout(init, 500);
            return;
        }

        try {
            const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.15/model/';
            
            // 2. Load the 3 required models
            await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
            await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
            await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);

            // 3. Start the camera
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: 640, height: 480, facingMode: "user" } 
            });
            video.srcObject = stream;
            
            video.onloadedmetadata = () => {
                spinner.style.display = 'none';
                statusBox.className = "status-badge bg-primary text-white";
                statusText.innerText = "Engine Ready - Look at Camera";
                btn.innerText = (action === 'ENROLL') ? "REGISTER MY FACE" : "VERIFY IDENTITY";
                btn.disabled = false;
            };

        } catch (e) {
            console.error("Setup Error:", e);
            spinner.style.display = 'none';
            statusBox.className = "status-badge bg-danger text-white";
            statusText.innerText = "Camera or Network Error";
        }
    }

    // Run the wait-and-init loop
    init();

    btn.onclick = async () => {
        btn.disabled = true;
        statusText.innerText = "Analyzing Face... Don't Move";
        
        // Stabilize frame
        await new Promise(r => setTimeout(r, 600));

        const detection = await faceapi.detectSingleFace(video).withFaceLandmarks().withFaceDescriptor();
        
        if (!detection) {
            statusText.innerText = "Face not found. Center your face.";
            btn.disabled = false;
            return;
        }

        const descriptor = Array.from(detection.
